{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently, I learned XGBoost by watching a series of the amazing videos host by [StatQuest with Josh Starmer](https://www.youtube.com/watch?v=OtD8wVaFm6E). In this notebook, I summary what I have learned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How does XGBoost work\n",
    "\n",
    "XGBoost builds a model by construcing a series of decision binary trees with each trees fitted to the residual of the previous trees. The output of XGBoost is the combination of these trees. The initial tree, ususally, is just a naive guess. However, after several trees are built, XGBoost can fit the traing data very well.\n",
    "The residual is just the difference between the targets and predictions of the trees that have been constructed.\n",
    "\n",
    "Then in order understand how XGBoost works, we should understand two questions:\n",
    "1. how to split a leaf\n",
    "1. how to make a prediction.\n",
    "\n",
    "\n",
    "Since, on the surface, the other two answers are different on regression and classification,\n",
    "XGBoost will be explained in Regression and Classification respectively.\n",
    "\n",
    "## 1.1 XGBoost: regression\n",
    "\n",
    "### 1.1.1 Using Similarity and Gain to construct a binary tree fitted to residuals\n",
    "\n",
    "Denote the residuals of the $n$ samples in a leaf by $r_i$ with i=1,...,n.\n",
    "Then we can calculate the **Similarity Score**, $S$ of the leaf as follows\n",
    "\\begin{equation}\n",
    " S = { (\\Sigma_{i=1}^n r_i)^2 \\over n + \\lambda},\n",
    "\\end{equation}\n",
    "where $\\lambda$ is a regularization parameter.\n",
    "Then we try to find a threshold to split the leaf into two leaves (left and right)\n",
    "and calculate the similarities scores on the two leaves and denoting them as $S_l$ and $S_r$.\n",
    "Then we can calculate the **Gain** for this split:\n",
    "$$\n",
    "G = S_l + S_r - S.\n",
    "$$\n",
    "Then we can try different threshold to split the leaf and select the threshold with the largest gain\n",
    "to split the leaf. Repeating this procedure, we can construnct a binary tree fitted to the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 The predictions of XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
