{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read a vert interesting blogs, [How we can make machine learning algorithm tunable](https://engraved.ghost.io/how-we-can-make-machine-learning-algorithms-tunable/), post Engraved by J. Degrave and I. Korshunova. \n",
    "Here, I summary the result and give my understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Solve-The-Dual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(θ, λ, ε):\n",
    "  return loss_1(θ) - λ*(ε - loss_2(θ))\n",
    "\n",
    "loss_derivative = grad(loss)\n",
    "ε = 0.3 \n",
    "λ = solve_dual(ε)  # The crux\n",
    "\n",
    "for gradient_step in range(200):\n",
    "  gradient = loss_derivative(θ, λ, ε)\n",
    "  θ = θ - 0.02 * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not work, since this is just the origin linear trade-off between two losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hard Constraint First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint(θ, ε):\n",
    "  return ε - loss_2(θ)\n",
    "\n",
    "optimization_derivative = grad(loss_1)\n",
    "constraint_derivative = grad(constraint)\n",
    "\n",
    "ε = 0.7\n",
    "\n",
    "for gradient_step in range(200):\n",
    "  while constraint(θ, ε) < 0:\n",
    "    # maximize until the constraint is positive again\n",
    "    gradient = constraint_derivative(θ, ε)\n",
    "    θ = θ + 0.02 * gradient\n",
    "    \n",
    "  gradient = optimization_derivative(θ)\n",
    "  θ = θ - 0.02 * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration of this method, firstly, $\\theta$ is changed iteratively to make the constraint condition being\n",
    "satisfied. So, actually, loss_1 will not effect until the constraint condition is satisfied. And once the constraint\n",
    "is violated, the constraint would take over the control until it becomes satisfied again.\n",
    "\n",
    "The authors said:  \n",
    "\"Additionally, this method does not work that well when you want to use stochastic gradient descent rather than gradient descent. Since the constraint is defined on the average loss across all data, you do not want to enforce the hard constraint on a sample of your data where it is not satisfied yet, as long as it is satisfied in the general case. And this issue is hard to overcome.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Differential Multiplier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrangian(θ, λ, ε):\n",
    " return loss_1(θ) - λ*(ε - loss_2(θ))\n",
    "\n",
    "derivative = grad(lagrangian, (0,1))\n",
    "ε = 0.7\n",
    "λ = 0.0\n",
    "\n",
    "for gradient_step in range(200):\n",
    "  gradient_θ, gradient_λ = derivative(θ,λ,ε)\n",
    "  θ = θ - 0.02 * gradient_θ  # Gradient descent\n",
    "  λ = λ + gradient_λ  # Gradient ascent!\n",
    "  if λ < 0:\n",
    "    λ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This elegantly optimizes the parameters by increasing the effect of loss_2 when the constarint is not satisfied\n",
    "and decreasing the effect of loss_2 when the constraint is violated automatically .\n",
    "\n",
    "But it would oscilate on the concave Pareto front and does not converge to a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Differential Method of Multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrangian(θ, λ, ε):\n",
    " damp = 10 * stop_gradient(ε-loss_2(θ))\n",
    " return loss_1(θ) - (λ-damp) * (ε-loss_2(θ))\n",
    "\n",
    "derivative = grad(lagrangian, (0,1))\n",
    "ε = 0.7\n",
    "λ = 0.0\n",
    "\n",
    "for gradient_step in range(200):\n",
    "  gradient_θ, gradient_λ = derivative(θ, λ, ε)\n",
    "  θ = θ - 0.02 * gradient_θ\n",
    "  λ = λ + gradient_λ\n",
    "  if λ < 0:\n",
    "    λ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the constraint is not satisfied, \"damp\" would be negative to accelerate the optimization of $\\theta$\n",
    "to satisfy the constraint. Once the constraint is satisfied, \"damp\" would be positive to damping the effect of \"loss_2\".\n",
    "In this way, the oscilation the concave Pareto front will be damped out.\n",
    "\n",
    "This method works well on both convex and concav Parento fronts.\n",
    "\n",
    "My question is how about not using \"damp\", but change the last \"if\" condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrangian(θ, λ, ε):\n",
    " damp = 10 * stop_gradient(ε-loss_2(θ))\n",
    " return loss_1(θ) - λ * (ε-loss_2(θ))\n",
    "\n",
    "derivative = grad(lagrangian, (0,1))\n",
    "ε = 0.7\n",
    "λ = 0.0\n",
    "\n",
    "for gradient_step in range(200):\n",
    "  gradient_θ, gradient_λ = derivative(θ, λ, ε)\n",
    "  θ = θ - 0.02 * gradient_θ\n",
    "  λ = λ + gradient_λ\n",
    "  if λ < 0 or gradient_λ < 0: # when gradient_λ is negative set λ to be zero\n",
    "    λ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sine \"gradient_λ < 0\" means that the constraint is satisfied, we can set λ=0 to delete the effect of loss_2 once it holds. But I am not sure whether this way would work better or worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
